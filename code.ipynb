{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nazario_5.csv',\n",
       " 'Nigerian_Fraud.csv',\n",
       " 'Ling.csv',\n",
       " 'TREC_05.csv',\n",
       " 'TREC_06.csv',\n",
       " 'TREC_07.csv',\n",
       " 'Nazario.csv',\n",
       " 'SpamAssasin.csv',\n",
       " 'CEAS_08.csv',\n",
       " 'Nigerian_5.csv',\n",
       " 'Enron.csv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_csv_files(directory):\n",
    "    # List to hold csv file names\n",
    "    csv_files = []\n",
    "    \n",
    "    # Iterate over files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Check if the file is a CSV\n",
    "        if filename.endswith('.csv'):\n",
    "            csv_files.append(filename)\n",
    "    \n",
    "    return csv_files\n",
    "\n",
    "\n",
    "folder_path = '/Users/rachels/Desktop/NUS/Y4/dsa4266/Phishing data'\n",
    "csv_files = list_csv_files(\"/Users/rachels/Desktop/NUS/Y4/dsa4266/Phishing data\")\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nazario_5.csv\n",
      "Nazario_5.csv\n",
      "(3065, 7)\n",
      "Index(['sender', 'receiver', 'date', 'subject', 'body', 'label', 'urls'], dtype='object')\n",
      "Nigerian_Fraud.csv\n",
      "Nigerian_Fraud.csv\n",
      "(3332, 7)\n",
      "Index(['sender', 'receiver', 'date', 'subject', 'body', 'urls', 'label'], dtype='object')\n",
      "Ling.csv\n",
      "Ling.csv\n",
      "(2859, 3)\n",
      "Index(['subject', 'body', 'label'], dtype='object')\n",
      "TREC_05.csv\n",
      "TREC_06.csv\n",
      "TREC_07.csv\n",
      "Nazario.csv\n",
      "Nazario.csv\n",
      "(1565, 7)\n",
      "Index(['sender', 'receiver', 'date', 'subject', 'body', 'urls', 'label'], dtype='object')\n",
      "SpamAssasin.csv\n",
      "SpamAssasin.csv\n",
      "(5809, 7)\n",
      "Index(['sender', 'receiver', 'date', 'subject', 'body', 'label', 'urls'], dtype='object')\n",
      "CEAS_08.csv\n",
      "CEAS_08.csv\n",
      "(39154, 7)\n",
      "Index(['sender', 'receiver', 'date', 'subject', 'body', 'label', 'urls'], dtype='object')\n",
      "Nigerian_5.csv\n",
      "Nigerian_5.csv\n",
      "(6331, 7)\n",
      "Index(['sender', 'receiver', 'date', 'subject', 'body', 'label', 'urls'], dtype='object')\n",
      "Enron.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r7/7xn5t9gj65x3tw58b7rmvtmm0000gn/T/ipykernel_42668/2702194472.py:6: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enron.csv\n",
      "(49152, 423)\n",
      "Index(['subject', 'body', 'label', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5',\n",
      "       'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9',\n",
      "       ...\n",
      "       'Unnamed: 413', 'Unnamed: 414', 'Unnamed: 415', 'Unnamed: 416',\n",
      "       'Unnamed: 417', 'Unnamed: 418', 'Unnamed: 419', 'Unnamed: 420',\n",
      "       'Unnamed: 421', 'Unnamed: 422'],\n",
      "      dtype='object', length=423)\n"
     ]
    }
   ],
   "source": [
    "for file in csv_files:\n",
    "    if 'TREC' in file:\n",
    "        continue\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(file)\n",
    "    print(df.shape)\n",
    "    print(df.columns)\n",
    "    # print(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r7/7xn5t9gj65x3tw58b7rmvtmm0000gn/T/ipykernel_42668/3066427877.py:6: DtypeWarning: Columns (2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "# combine all the datasets into one\n",
    "combined = []\n",
    "for file in csv_files:\n",
    "    if 'TREC' in file:\n",
    "        continue\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    if df.shape[1] == 7:\n",
    "        df = df[['sender', 'receiver', 'date', 'subject', 'body', 'urls', 'label']]\n",
    "        combined.append(df)\n",
    "\n",
    "df = pd.read_csv(os.path.join(folder_path, 'TREC_07.csv')) \n",
    "df = df[['sender', 'receiver', 'date', 'subject', 'body', 'urls', 'label']]\n",
    "combined.append(df)\n",
    "combined_df = pd.concat(combined, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sender', 'receiver', 'date', 'subject', 'body', 'urls', 'label'], dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.concat(combined, ignore_index=True)\n",
    "combined_df.head()\n",
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering for body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  \n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Counts the number of characters in a given string\n",
    "def count_characters(string):\n",
    "    return len(string) - string.count(' ') - string.count('\\n')\n",
    "\n",
    "# Integer: number of words in the body\n",
    "def body_noWords(body_content):\n",
    "    body_noWords = len(body_content.split())\n",
    "    return body_noWords\n",
    "\n",
    "# Integer: number of characters in the body\n",
    "def body_noCharacters(body_content):\n",
    "    body_noCharacters = count_characters(body_content)\n",
    "    return body_noCharacters\n",
    "\n",
    "# Integer: number of distinct words in the body\n",
    "def body_noDistinctWords(body_content):\n",
    "    body_noDistinctWords = len(Counter(body_content.split()))\n",
    "    return body_noDistinctWords\n",
    "\n",
    "# Float: richness of the text (body)\n",
    "def body_richness(body_noWords, body_noCharacters):\n",
    "    try:\n",
    "        body_richness = float(body_noWords)/body_noCharacters\n",
    "    except:\n",
    "        body_richness = 0\n",
    "    return body_richness\n",
    "\n",
    "# Integer: number of function words in the body\n",
    "def body_noFunctionWords(body_content):\n",
    "    body_noFunctionWords = 0\n",
    "    wordlist = re.sub(\"[^A-Za-z]\", \" \", body_content.strip()).lower().split()\n",
    "    function_words = [\"account\", \"access\", \"bank\", \"credit\", \"click\", \"identity\", \"inconvenience\", \"information\", \"limited\", \n",
    "                      \"log\", \"minutes\", \"password\", \"recently\", \"risk\", \"social\", \"security\", \"service\", \"suspended\"]\n",
    "    for word in function_words:\n",
    "        body_noFunctionWords += wordlist.count(word)\n",
    "    return body_noFunctionWords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to extract attributes from the mail body\n",
    "def extract_body_attributes(df):    \n",
    "    df['body_noWords'] = df['body'].apply(body_noWords)\n",
    "    df['body_noCharacters'] = df['body'].apply(body_noCharacters) \n",
    "    df['body_noDistinctWords'] = df['body'].apply(body_noDistinctWords)\n",
    "    df['body_richness'] = df.apply(lambda row: body_richness(row['body_noWords'], row['body_noCharacters']), axis=1)\n",
    "    df['body_noFunctionWords'] = df['body'].apply(body_noFunctionWords)\n",
    "    return df\n",
    "\n",
    "combined_df['body'] = combined_df['body'].fillna(\"\")\n",
    "combined_df = extract_body_attributes(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering for Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Functions to extract subject line based attributes\n",
    "'''\n",
    "# Boolean: Check if the email is a reply to any previous mail\n",
    "def subj_reply(subj_content):\n",
    "    subj_reply = subj_content.lower().startswith(\"re:\")\n",
    "    return subj_reply\n",
    "\n",
    "# Boolean: Check if the email is a forward from another mail\n",
    "def subj_forward(subj_content):\n",
    "    subj_forward = subj_content.lower().startswith(\"fwd:\")\n",
    "    return subj_forward\n",
    "\n",
    "# Integer: number of words in the subject\n",
    "def subj_noWords(subj_content):\n",
    "    subj_noWords = len(subj_content.split())\n",
    "    return subj_noWords\n",
    "\n",
    "# Integer: number of characters in the subject\n",
    "def subj_noCharacters(subj_content):\n",
    "    subj_noCharacters = count_characters(subj_content)\n",
    "    return subj_noCharacters\n",
    "\n",
    "# Float: richness of the text (subject)\n",
    "def subj_richness(subj_noWords, subj_noCharacters):\n",
    "    try:\n",
    "        subj_richness = float(subj_noWords)/subj_noCharacters\n",
    "    except:\n",
    "        subj_richness = 0\n",
    "    return subj_richness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Extract subject line based attributes\n",
    "'''\n",
    "\n",
    "# Run the function to extract attributes from the mail subject line\n",
    "def extract_subj_attributes(df):\n",
    "    \n",
    "    df['subj_reply'] = df['subject'].apply(subj_reply) \n",
    "    df['subj_forward'] = df['subject'].apply(subj_forward)\n",
    "    df['subj_noWords'] = df['subject'].apply(subj_noWords)\n",
    "    df['subj_noCharacters'] = df['subject'].apply(subj_noCharacters)\n",
    "    df['subj_richness'] = df.apply(lambda row: subj_richness(row['subj_noWords'], row['subj_noCharacters']), axis=1)\n",
    "    return df\n",
    "\n",
    "combined_df['subject'] = combined_df['subject'].fillna(\"\")\n",
    "combined_df = extract_subj_attributes(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
